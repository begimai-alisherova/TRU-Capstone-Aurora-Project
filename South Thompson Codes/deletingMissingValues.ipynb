{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f983c17",
   "metadata": {},
   "source": [
    "The code processes large CSV files in chunks to handle missing values efficiently. The first part identifies missing values by counting rows and columns with missing data and provides a summary of their distribution. The second part removes rows with missing values, saving the cleaned dataset incrementally to a new file. This approach ensures memory efficiency while working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e274563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edc4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the dataset: 29558877\n",
      "Total rows with missing values: 2558477\n",
      "Total rows without missing values: 27000400\n",
      "\n",
      "Total columns in the dataset: 25\n",
      "Columns with missing values: 23\n",
      "Columns without missing values: 2\n",
      "\n",
      "Columns with missing values and their counts:\n",
      "Convergence: 2148117\n",
      "MRVBF: 2144611\n",
      "MRRTF: 2144611\n",
      "DAH: 2144611\n",
      "Curvature_Total: 2148117\n",
      "Curvature_General: 2148117\n",
      "Aspect: 2148117\n",
      "O_flow_x: 2380628\n",
      "O_flow_horiz: 2380628\n",
      "O_flow_vert: 2380628\n",
      "Openness_neg: 2216650\n",
      "O_flow_y: 2216650\n",
      "TPI: 2144611\n",
      "TRI: 2144611\n",
      "Vert_disc_cn: 2144611\n",
      "Slope: 2144611\n",
      "TWI: 2144611\n",
      "CTVI: 136090\n",
      "MSAVI: 136090\n",
      "NDVI: 135263\n",
      "rvi: 136090\n",
      "msavi2: 136090\n",
      "GNDVI Value: 134546\n"
     ]
    }
   ],
   "source": [
    "##MISSING VALUES - where? how many?\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = r'C:/Users/T00701453/Downloads/combined.csv'\n",
    "chunk_size = 10**6  # Adjust chunk size as needed\n",
    "\n",
    "# Initialize counters\n",
    "total_rows = 0\n",
    "rows_with_missing_values = 0\n",
    "rows_without_missing_values = 0\n",
    "\n",
    "# Dictionary to store the count of missing values per column\n",
    "missing_values_per_column = {}\n",
    "\n",
    "# Process the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # Update the total row count\n",
    "    total_rows += chunk.shape[0]\n",
    "    \n",
    "    # Count rows with and without missing values in the current chunk\n",
    "    rows_with_missing_in_chunk = chunk[chunk.isnull().any(axis=1)].shape[0]\n",
    "    rows_with_missing_values += rows_with_missing_in_chunk\n",
    "    rows_without_missing_values += chunk.shape[0] - rows_with_missing_in_chunk\n",
    "    \n",
    "    # Count missing values per column in the current chunk and update totals\n",
    "    for column in chunk.columns:\n",
    "        missing_count = chunk[column].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            if column in missing_values_per_column:\n",
    "                missing_values_per_column[column] += missing_count\n",
    "            else:\n",
    "                missing_values_per_column[column] = missing_count\n",
    "\n",
    "# Calculate total columns with and without missing values\n",
    "total_columns = len(missing_values_per_column.keys())\n",
    "columns_with_missing_values = len([col for col, count in missing_values_per_column.items() if count > 0])\n",
    "columns_without_missing_values = total_columns - columns_with_missing_values\n",
    "\n",
    "# Display results\n",
    "print(f\"Total rows in the dataset: {total_rows}\")\n",
    "print(f\"Total rows with missing values: {rows_with_missing_values}\")\n",
    "print(f\"Total rows without missing values: {rows_without_missing_values}\")\n",
    "\n",
    "print(f\"\\nTotal columns in the dataset: {len(chunk.columns)}\")\n",
    "print(f\"Columns with missing values: {columns_with_missing_values}\")\n",
    "print(f\"Columns without missing values: {len(chunk.columns) - columns_with_missing_values}\")\n",
    "\n",
    "print(\"\\nColumns with missing values and their counts:\")\n",
    "for column, missing_count in missing_values_per_column.items():\n",
    "    print(f\"{column}: {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caf44b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows without missing values have been saved to C:/Users/T00701453/Downloads/combined_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "##MISSING VALUES --deletion\n",
    "\n",
    "# Path for the cleaned CSV file (without missing values)\n",
    "cleaned_file_path = r'C:/Users/T00701453/Downloads/combined_cleaned.csv'\n",
    "chunk_size = 10**6  # Load 1 million rows at a time; adjust as needed\n",
    "\n",
    "# Process the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # Drop rows with any missing values in the current chunk\n",
    "    chunk_cleaned = chunk.dropna()\n",
    "    \n",
    "    # Append the cleaned chunk to the new CSV file\n",
    "    # Write header only for the first chunk\n",
    "    chunk_cleaned.to_csv(cleaned_file_path, mode='a', index=False, header=not pd.io.common.file_exists(cleaned_file_path))\n",
    "\n",
    "print(f\"Rows without missing values have been saved to {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
