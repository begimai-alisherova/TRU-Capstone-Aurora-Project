{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3273c6bf",
   "metadata": {},
   "source": [
    "Final version of our pipeline. The code implements a machine learning pipeline using a Random Forest classifier for geospatial data. It begins by merging a ground truth dataset with a larger dataset on Latitude and Longitude. The merged data is preprocessed by separating features and target labels, scaling the features, and splitting the data into training and testing sets. The Random Forest model is trained on the training data, and its accuracy is evaluated on the test set. Feature importance is calculated and ranked to identify the most influential features. Further, the pipeline includes feature selection using statistical methods (e.g., ANOVA F-value) to optimize the input features. The model is retrained using the selected features, and additional features are incorporated iteratively to improve accuracy. Then, hyperparameter tuning with GridSearchCV is used for optimization. The tuned model is evaluated on metrics such as accuracy, precision, recall, and F1-score, with a classification report providing detailed performance insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb9478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 69.44%\n",
      "                                 importance\n",
      "Terrain_mrvbf                      0.070032\n",
      "Terrain_tri                        0.067357\n",
      "Terrain_openness_pos               0.061438\n",
      "Terrain_aspect                     0.056668\n",
      "Terrain_tpi                        0.053253\n",
      "Terrain_slope                      0.050433\n",
      "Terrain_hcurv                      0.049810\n",
      "Terrain_vcurv                      0.048956\n",
      "Terrain_mrrtf                      0.048575\n",
      "Terrain_convergence                0.038960\n",
      "Terrain_openness_neg               0.035214\n",
      "Terrain_ls_factor                  0.035119\n",
      "Terrain_tca                        0.032157\n",
      "MS_MSAVI                           0.031763\n",
      "Terrain_valley_depth               0.031604\n",
      "MS_MSAVI2                          0.030105\n",
      "MS_GNDVI                           0.028789\n",
      "Terrain_dah                        0.027752\n",
      "Terrain_twi                        0.026979\n",
      "NDVI                               0.026188\n",
      "Terrain_chnl_dist                  0.026075\n",
      "Terrain_relative_slope_position    0.026051\n",
      "MS_RVI                             0.025868\n",
      "Terrain_chnl_base                  0.025396\n",
      "MS_EVI                             0.024477\n",
      "MS_NDWI                            0.020981\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ground_truth_file = r'C:/Users/T00667334/Downloads/gt.csv'  # Replace with your ground truth file name\n",
    "all_data_file = r'C:/Users/T00667334/Downloads/combined.csv' \n",
    "\n",
    "# Load the data\n",
    "ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "all_data_df = pd.read_csv(all_data_file)\n",
    "\n",
    "# Merge data\n",
    "merged_df = pd.merge(all_data_df, ground_truth_df, on=['Latitude', 'Longitude'], how='inner')\n",
    "\n",
    "# Prepare features and target\n",
    "X = merged_df.drop(columns=['Latitude', 'Longitude', 'Labels'])  # Drop non-feature columns\n",
    "y = merged_df['Labels']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get feature importances and create DataFrame with feature names\n",
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   index=X.columns,  # Use the original column names\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944470ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Latitude', 'Terrain_convergence', 'Terrain_ls_factor', 'Terrain_mrrtf',\n",
      "       'Terrain_mrvbf', 'Terrain_openness_neg', 'Terrain_openness_pos',\n",
      "       'Terrain_slope', 'Terrain_tca', 'Terrain_tri'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = merged_df\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop('Labels', axis=1)  # Drop the target column from features\n",
    "y = data['Labels']  # Assign the target column to y\n",
    "\n",
    "# Select the top k best features based on f_classif (ANOVA F-value)\n",
    "selector = SelectKBest(f_classif, k=10)  # You can change k based on your needs\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a302d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Train a new Random Forest model using only the selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.25, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8de529",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = ['NDVI','MS_GNDVI', 'Longitude', 'Terrain_aspect', 'Terrain_twi', 'Terrain_tpi', 'MS_MSAVI', 'Terrain_hcurv', 'Terrain_vcurv','MS_MSAVI2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c143a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = list(selected_features) + add_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c004590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[final_features], y, test_size=0.20, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10c55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\t00667334\\appdata\\roaming\\python\\python39\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6a44140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Precision: 0.78\n",
      "Recall: 0.79\n",
      "F1 Score: 0.77\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87        35\n",
      "           1       0.71      0.38      0.50        13\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.76      0.66      0.68        48\n",
      "weighted avg       0.78      0.79      0.77        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score with weighted average (use 'binary' for binary classification)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero recall cases\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero F1 score cases\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "679a74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Improved Accuracy with Tuned Random Forest: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid for Random Forest tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],      # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],            # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],            # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],              # Minimum number of samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Use the best model found by GridSearchCV\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict with the tuned model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Improved Accuracy with Tuned Random Forest: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef19ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.80\n",
      "Recall: 0.81\n",
      "F1 Score: 0.80\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88        35\n",
      "           1       0.75      0.46      0.57        13\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.79      0.70      0.73        48\n",
      "weighted avg       0.80      0.81      0.80        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score with weighted average (use 'binary' for binary classification)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero recall cases\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)  # Add zero_division to handle zero F1 score cases\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
